<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>FLARES: Fast and Accurate LiDAR Multi-Range Semantic Segmentation</title>
  <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
</head>
<body class="bg-gray-50 text-gray-800">

  <!-- Header Section -->
  <header class="text-center py-12">
    <h1 class="text-4xl md:text-5xl font-bold mb-4 leading-tight">
      <span class="text-orange-600 italic">FLARES</span>:<br>
      Fast and Accurate LiDAR Multi-Range Semantic Segmentation
    </h1>

    <!-- Authors + Affiliations -->
    <p class="text-lg text-gray-700">
      Bin Yang<sup>1,2</sup> · Alexandru Paul Condurache<sup>1,2</sup>
    </p>
    <p class="text-sm text-gray-600 mt-2">
      <sup>1</sup>Automated Driving Research, Robert Bosch GmbH&nbsp;&nbsp;·&nbsp;&nbsp;
      <sup>2</sup>Institute of Signal Processing, University of Lübeck
    </p>

    <!-- Buttons -->
    <div class="space-x-3 mt-6">
      <a href="https://arxiv.org/pdf/2502.09274" class="px-4 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition">Paper</a>
      <a href="https://github.com/yourusername/FLARES" class="px-4 py-2 bg-gray-800 text-white rounded-lg hover:bg-gray-900 transition">Code</a>
      <a href="https://arxiv.org/abs/2502.09274" class="px-4 py-2 bg-red-600 text-white rounded-lg hover:bg-red-700 transition">Arxiv</a>
      <!-- <a href="https://yourdatasetlink.com" class="px-4 py-2 bg-green-600 text-white rounded-lg hover:bg-green-700 transition">Dataset</a> -->
    </div>
  </header>

  <!-- Teaser: three figures in parallel -->
  <section class="max-w-5xl mx-auto mb-12 px-4">
    <div class="grid grid-cols-3 md:grid-cols-1 gap-6">
      <figure class="bg-white rounded-lg shadow overflow-hidden">
        <img src="images/standard.svg" alt="Multi-range splitting of the panorama" class="w-full h-auto object-cover">
        <figcaption class="text-sm text-gray-600 p-3 text-center">
          (a) Standard
        </figcaption>
      </figure>
      <figure class="bg-white rounded-lg shadow overflow-hidden">
        <img src="images/str.svg" alt="Training with multi-range images" class="w-full h-auto object-cover">
        <figcaption class="text-sm text-gray-600 p-3 text-center">
          (b) STR <a href="https://arxiv.org/abs/2303.05367" target="_blank" class="text-blue-600 underline">Kong et al., 2023</a>.
        </figcaption>
      </figure>
      <figure class="bg-white rounded-lg shadow overflow-hidden">
        <img src="images/flares.svg" alt="Post-processing for multi-range fusion" class="w-full h-auto object-cover">
        <figcaption class="text-sm text-gray-600 p-3 text-center">
          <strong><em>(c) FLARES </em></strong> 
        </figcaption>
      </figure>
    </div>
    <p class="text-center text-gray-500 mt-3 text-sm"><strong>Figure 1.</strong>
  <em>Visual comparison among different training procedures for range-view LiDAR semantic segmentation:</em>
  <span class="text-red-600 font-semibold text-2xl">①</span> Splitting,
  <span class="text-red-600 font-semibold text-2xl">②</span> Range-view projection,
  <span class="text-red-600 font-semibold text-2xl">③</span> Network prediction,
  <span class="text-red-600 font-semibold text-2xl">④</span> Post-processing,
  <span class="text-red-600 font-semibold text-2xl">⑤</span> Image concatenation.</p>
  </section>

  <!-- Abstract -->
  <section class="max-w-3xl mx-auto mb-10 px-4">
    <h2 class="text-2xl font-semibold mb-4 text-center">Abstract</h2>
    <p class="text-justify text-gray-700 leading-relaxed">
      3D scene understanding is a critical yet challenging task in autonomous driving due to the irregularity and sparsity of LiDAR data, as well as the computational demands of processing large-scale point clouds. Recent methods leverage range-view representations to enhance efficiency, but they often adopt higher azimuth resolutions to mitigate information loss during spherical projection, where only the closest point is retained for each 2D grid.
      However, processing wide panoramic range-view images remains inefficient and may introduce additional distortions. Our empirical analysis shows that training with multiple range images, obtained from splitting the full point cloud, improves both segmentation accuracy and computational efficiency. However, this approach also poses new challenges of exacerbated class imbalance and increase in projection artifacts.
      To address these, we introduce <span class="font-semibold text-orange-600">FLARES</span>, a novel training paradigm that incorporates two tailored data augmentation techniques and a specialized post-processing method designed for multi-range settings. Extensive experiments demonstrate that FLARES is highly generalizable across different architectures, yielding 2.1–7.9% mIoU improvements on SemanticKITTI and 1.8–3.9% mIoU on nuScenes, while delivering over 40% speed-up in inference.
    </p>
  </section>

<section class="max-w-6xl mx-auto mb-16 px-4">
  <h2 class="text-2xl font-semibold mb-6 text-center">Video Presentations</h2>

  <div class="grid grid-cols-1 md:grid-cols-2 gap-8">

    <!-- Video 1 -->
    <div class="text-center">
      <div class="aspect-w-16 aspect-h-9">
        <iframe class="w-full h-full rounded-lg shadow-lg"
                src="https://www.youtube.com/embed/nGlI5MmLFaU"
                frameborder="0"
                referrerpolicy="strict-origin-when-cross-origin"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; fullscreen"></iframe>

      </div>
      <p class="mt-3 text-sm text-gray-700 font-semibold italic">
        (a) Demo: Multi-range splitting process.
      </p>
    </div>

    <!-- Video 2 -->
    <div class="text-center">
      <div class="aspect-w-16 aspect-h-9">
        <iframe class="w-full h-full rounded-lg shadow-lg"
                src="https://www.youtube.com/embed/VIDEO_ID_2"
                frameborder="0" allowfullscreen></iframe>
      </div>
      <p class="mt-3 text-sm text-gray-700 font-semibold italic">
        (b) Demo: Range-view projection.
      </p>
    </div>

    <!-- Video 3 -->
    <div class="text-center">
      <div class="aspect-w-16 aspect-h-9">
        <iframe class="w-full h-full rounded-lg shadow-lg"
                src="https://www.youtube.com/embed/VIDEO_ID_3"
                frameborder="0" allowfullscreen></iframe>
      </div>
      <p class="mt-3 text-sm text-gray-700 font-semibold italic">
        (c) Demo: Network predictions across ranges.
      </p>
    </div>

    <!-- Video 4 -->
    <div class="text-center">
      <div class="aspect-w-16 aspect-h-9">
        <iframe class="w-full h-full rounded-lg shadow-lg"
                src="https://www.youtube.com/embed/VIDEO_ID_4"
                frameborder="0" allowfullscreen></iframe>
      </div>
      <p class="mt-3 text-sm text-gray-700 font-semibold italic">
        (d) Demo: Final fused result.
      </p>
    </div>

  </div>
</section>


  <!-- Results
  <section class="max-w-6xl mx-auto mb-16 px-4">
    <h2 class="text-2xl font-semibold mb-6 text-center">Qualitative Results</h2>
    <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
      <img src="images/result1.png" alt="Result 1" class="rounded-lg shadow-md">
      <img src="images/result2.png" alt="Result 2" class="rounded-lg shadow-md">
      <img src="images/result3.png" alt="Result 3" class="rounded-lg shadow-md">
      <img src="images/result4.png" alt="Result 4" class="rounded-lg shadow-md">
    </div>
  </section> -->

  <!-- Citation -->
  <section class="bg-gray-100 py-12">
    <div class="max-w-3xl mx-auto px-4">
      <h2 class="text-2xl font-semibold mb-4 text-center">BibTeX</h2>
      <pre class="bg-gray-800 text-gray-100 p-4 rounded-lg text-sm overflow-x-auto">
@inproceedings{yang2026flares,
  title={FLARES: Fast and Accurate LiDAR Multi-Range Semantic Segmentation},
  author={Bin Yang and Alexandru Paul Condurache},
  booktitle={The IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  year={2026}
}
      </pre>
    </div>
  </section>

  <!-- Footer -->
  <footer class="text-center text-gray-500 text-sm py-8">
    © 2025 Bin Yang. Template inspired by academic project pages (CVPR/ICCV style).
  </footer>

</body>
</html>
