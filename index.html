<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>FLARES: Fast and Accurate LiDAR Multi-Range Semantic Segmentation</title>
  <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
</head>
<body class="bg-gray-50 text-gray-800">

  <!-- Header Section -->
  <header class="text-center py-12">
    <h1 class="text-4xl md:text-5xl font-bold mb-4">
      <span class="text-orange-600 italic">FLARES</span>:<br>
      Fast and Accurate LiDAR Multi-Range Semantic Segmentation
    </h1>
    <p class="text-lg text-gray-600 mb-6">Bin Yang · Alexandru Paul Condurache</p>
    <div class="space-x-3">
      <a href="https://arxiv.org/abs/xxxx.xxxxx" class="px-4 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition">Paper</a>
      <a href="https://github.com/yourusername/FLARES" class="px-4 py-2 bg-gray-800 text-white rounded-lg hover:bg-gray-900 transition">Code</a>
      <a href="https://youtu.be/yourvideoid" class="px-4 py-2 bg-red-600 text-white rounded-lg hover:bg-red-700 transition">Video</a>
      <a href="https://yourdatasetlink.com" class="px-4 py-2 bg-green-600 text-white rounded-lg hover:bg-green-700 transition">Dataset</a>
    </div>
  </header>

  <!-- Teaser Image -->
  <section class="max-w-5xl mx-auto mb-12 px-4">
    <img src="teaser.png" alt="Project Teaser" class="rounded-lg shadow-lg mx-auto">
    <p class="text-center text-gray-500 mt-3 text-sm">Figure 1. Overview of our FLARES framework.</p>
  </section>

  <!-- Abstract -->
  <section class="max-w-3xl mx-auto mb-16 px-4">
    <h2 class="text-2xl font-semibold mb-4 text-center">Abstract</h2>
    <p class="text-justify text-gray-700 leading-relaxed">
      3D scene understanding is a critical yet challenging task in autonomous driving due to the irregularity and sparsity of LiDAR data, as well as the computational demands of processing large-scale point clouds. Recent methods leverage range-view representations to enhance efficiency, but they often adopt higher azimuth resolutions to mitigate information loss during spherical projection, where only the closest point is retained for each 2D grid.
      However, processing wide panoramic range-view images remains inefficient and may introduce additional distortions. Our empirical analysis shows that training with multiple range images, obtained from splitting the full point cloud, improves both segmentation accuracy and computational efficiency. However, this approach also poses new challenges of exacerbated class imbalance and increase in projection artifacts.
      To address these, we introduce <span class="font-semibold text-orange-600">FLARES</span>, a novel training paradigm that incorporates two tailored data augmentation techniques and a specialized post-processing method designed for multi-range settings. Extensive experiments demonstrate that FLARES is highly generalizable across different architectures, yielding 2.1–7.9% mIoU improvements on SemanticKITTI and 1.8–3.9% mIoU on nuScenes, while delivering over 40% speed-up in inference.
    </p>
  </section>

  <!-- Video -->
  <section class="max-w-5xl mx-auto mb-16 text-center px-4">
    <h2 class="text-2xl font-semibold mb-6">Video Presentation</h2>
    <div class="aspect-w-16 aspect-h-9">
      <iframe class="w-full h-96 rounded-lg shadow-lg" src="https://www.youtube.com/embed/yourvideoid" frameborder="0" allowfullscreen></iframe>
    </div>
  </section>

  <!-- Results -->
  <section class="max-w-6xl mx-auto mb-16 px-4">
    <h2 class="text-2xl font-semibold mb-6 text-center">Qualitative Results</h2>
    <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
      <img src="images/result1.png" alt="Result 1" class="rounded-lg shadow-md">
      <img src="images/result2.png" alt="Result 2" class="rounded-lg shadow-md">
      <img src="images/result3.png" alt="Result 3" class="rounded-lg shadow-md">
      <img src="images/result4.png" alt="Result 4" class="rounded-lg shadow-md">
    </div>
  </section>

  <!-- Citation -->
  <section class="bg-gray-100 py-12">
    <div class="max-w-3xl mx-auto px-4">
      <h2 class="text-2xl font-semibold mb-4 text-center">BibTeX</h2>
      <pre class="bg-gray-800 text-gray-100 p-4 rounded-lg text-sm overflow-x-auto">
@inproceedings{yang2026flares,
  title={FLARES: Fast and Accurate LiDAR Multi-Range Semantic Segmentation},
  author={Bin Yang and Alexandru Paul Condurache},
  booktitle={The IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  year={2026}
}
      </pre>
    </div>
  </section>

  <!-- Footer -->
  <footer class="text-center text-gray-500 text-sm py-8">
    © 2025 Bin Yang. Template inspired by academic project pages (CVPR/ICCV style).
  </footer>

</body>
</html>
